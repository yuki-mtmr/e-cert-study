import type { GlossaryTerm } from '@/types/glossary';

export const ML_TERMS: GlossaryTerm[] = [
  // パターン認識
  { id: 'knn', jaName: 'k近傍法', enName: 'k-Nearest Neighbors', description: '未知データに最も近いk個の訓練データの多数決で分類する手法。ノンパラメトリックで直感的。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'k-means', jaName: 'k-means法', enName: 'k-Means Clustering', description: 'データをk個のクラスタに分割する教師なし学習アルゴリズム。重心の更新を収束まで繰り返す。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'decision-tree', jaName: '決定木', enName: 'Decision Tree', description: '特徴量の条件分岐でデータを分類・回帰する木構造モデル。解釈性が高い。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'random-forest', jaName: 'ランダムフォレスト', enName: 'Random Forest', description: '複数の決定木を並列に学習させ多数決で予測するアンサンブル手法。過学習に強い。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'svm', jaName: 'サポートベクターマシン', enName: 'Support Vector Machine', description: 'クラス間のマージンを最大化する分類器。カーネルトリックで非線形分類も可能。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'kernel-trick', jaName: 'カーネルトリック', enName: 'Kernel Trick', description: '明示的に高次元空間に写像せずに内積計算を行う手法。SVMの非線形拡張を実現する。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'naive-bayes', jaName: 'ナイーブベイズ', enName: 'Naive Bayes', description: '特徴量の条件付き独立性を仮定したベイズ分類器。テキスト分類で広く使用される。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'logistic-regression', jaName: 'ロジスティック回帰', enName: 'Logistic Regression', description: 'シグモイド関数を用いた二値分類モデル。線形分類器の代表的手法。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'linear-regression', jaName: '線形回帰', enName: 'Linear Regression', description: '入力と出力の線形関係をモデル化する回帰手法。最小二乗法でパラメータを推定する。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  { id: 'gmm', jaName: '混合ガウスモデル', enName: 'Gaussian Mixture Model', description: '複数のガウス分布の重み付き和でデータ分布を表現するモデル。EMアルゴリズムで学習する。', sectionId: 'ml', subsectionId: 'ml-pattern' },
  // 機械学習の分類
  { id: 'supervised', jaName: '教師あり学習', enName: 'Supervised Learning', description: '入力と正解ラベルのペアから学習する手法。分類と回帰が主要なタスク。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'unsupervised', jaName: '教師なし学習', enName: 'Unsupervised Learning', description: 'ラベルなしデータから構造やパターンを発見する手法。クラスタリングや次元削減が代表的。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'semi-supervised', jaName: '半教師あり学習', enName: 'Semi-Supervised Learning', description: '少量のラベル付きデータと大量のラベルなしデータを組み合わせて学習する手法。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'self-supervised', jaName: '自己教師あり学習', enName: 'Self-Supervised Learning', description: 'データ自体から疑似的なラベルを生成して学習する手法。BERTのマスク言語モデルが代表例。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'reinforcement', jaName: '強化学習', enName: 'Reinforcement Learning', description: '環境との相互作用を通じて報酬を最大化する方策を学習する手法。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'classification', jaName: '分類', enName: 'Classification', description: '入力データを離散的なカテゴリに分ける教師あり学習タスク。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'regression-task', jaName: '回帰', enName: 'Regression', description: '入力データから連続値を予測する教師あり学習タスク。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'clustering', jaName: 'クラスタリング', enName: 'Clustering', description: 'データを類似度に基づきグループに分割する教師なし学習タスク。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'dimensionality-reduction', jaName: '次元削減', enName: 'Dimensionality Reduction', description: '高次元データを低次元に変換する手法。可視化や計算効率向上に使用される。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'feature-engineering', jaName: '特徴量エンジニアリング', enName: 'Feature Engineering', description: '生データからモデルに有用な特徴量を設計・抽出するプロセス。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'ensemble', jaName: 'アンサンブル学習', enName: 'Ensemble Learning', description: '複数のモデルを組み合わせて予測精度を向上させる手法。バギングとブースティングが代表的。', sectionId: 'ml', subsectionId: 'ml-class' },
  { id: 'boosting', jaName: 'ブースティング', enName: 'Boosting', description: '弱学習器を逐次的に学習し、前の学習器の誤りを補正するアンサンブル手法。', sectionId: 'ml', subsectionId: 'ml-class' },
  // 機械学習の課題
  { id: 'overfitting', jaName: '過学習', enName: 'Overfitting', description: '訓練データに過度に適合し、未知データへの汎化性能が低下する現象。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'underfitting', jaName: '未学習', enName: 'Underfitting', description: 'モデルの表現力が不足し、訓練データのパターンを十分に学習できていない状態。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'bias-variance', jaName: 'バイアス-バリアンストレードオフ', enName: 'Bias-Variance Tradeoff', description: 'モデルの複雑さに関するバイアスとバリアンスのトレードオフ。汎化誤差の分解に基づく。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'curse-of-dim', jaName: '次元の呪い', enName: 'Curse of Dimensionality', description: '高次元空間ではデータが疎になり、距離の概念が意味を失う現象。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'class-imbalance', jaName: 'クラス不均衡', enName: 'Class Imbalance', description: 'クラス間のサンプル数に大きな偏りがある問題。オーバーサンプリングやFocal Lossで対処する。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'data-augmentation', jaName: 'データ拡張', enName: 'Data Augmentation', description: '既存データに変換を加えて訓練データを増やす手法。回転・反転・クロップなどが代表的。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'missing-data', jaName: '欠損値処理', enName: 'Missing Data Handling', description: 'データの欠損に対処する手法。削除、平均値補完、多重代入法などがある。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'outlier', jaName: '外れ値', enName: 'Outlier', description: '他のデータから大きく外れた異常な値。モデルの学習に悪影響を与える場合がある。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'feature-scaling', jaName: '特徴量スケーリング', enName: 'Feature Scaling', description: '特徴量の値域を揃える前処理。標準化や最小最大スケーリングが代表的。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'label-noise', jaName: 'ラベルノイズ', enName: 'Label Noise', description: '訓練データのラベルに含まれる誤り。モデルの学習精度に悪影響を与える。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'covariate-shift', jaName: '共変量シフト', enName: 'Covariate Shift', description: '訓練時とテスト時で入力データの分布が異なる問題。ドメイン適応で対処する。', sectionId: 'ml', subsectionId: 'ml-issues' },
  { id: 'domain-adaptation', jaName: 'ドメイン適応', enName: 'Domain Adaptation', description: 'あるドメインで学習したモデルを別のドメインに適応させる手法。', sectionId: 'ml', subsectionId: 'ml-issues' },
  // 検証集合
  { id: 'train-test-split', jaName: '訓練・テスト分割', enName: 'Train-Test Split', description: 'データを訓練用とテスト用に分割して汎化性能を評価する基本的な方法。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'cross-validation', jaName: '交差検証', enName: 'Cross-Validation', description: 'データを複数に分割して訓練と検証を繰り返す評価手法。モデル選択に使用される。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'k-fold', jaName: 'k分割交差検証', enName: 'k-Fold Cross-Validation', description: 'データをk個に分割し、各分割をテストデータとしてk回評価する交差検証手法。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'holdout', jaName: 'ホールドアウト法', enName: 'Holdout Method', description: 'データを一度だけ訓練用とテスト用に分割する最もシンプルな評価方法。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'stratified', jaName: '層化抽出', enName: 'Stratified Sampling', description: 'クラス比率を保持したままデータを分割するサンプリング手法。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'hyperparameter', jaName: 'ハイパーパラメータ', enName: 'Hyperparameter', description: '学習前に設定するモデルの外部パラメータ。学習率やバッチサイズなどが代表的。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'grid-search', jaName: 'グリッドサーチ', enName: 'Grid Search', description: 'ハイパーパラメータの候補値を格子状に網羅的に探索する手法。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'random-search', jaName: 'ランダムサーチ', enName: 'Random Search', description: 'ハイパーパラメータの候補値をランダムにサンプリングして探索する手法。高次元で効率的。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'early-stopping', jaName: '早期終了', enName: 'Early Stopping', description: '検証誤差が悪化し始めたら学習を停止する正則化手法。過学習の防止に有効。', sectionId: 'ml', subsectionId: 'ml-validation' },
  { id: 'bayesian-optim', jaName: 'ベイズ最適化', enName: 'Bayesian Optimization', description: 'ガウス過程等を用いてハイパーパラメータを効率的に探索する手法。評価コストが高い場合に有効。', sectionId: 'ml', subsectionId: 'ml-validation' },
  // 性能指標
  { id: 'accuracy', jaName: '正解率', enName: 'Accuracy', description: '全予測のうち正解した割合。クラス不均衡時には適切でない場合がある。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'precision', jaName: '適合率', enName: 'Precision', description: '陽性と予測したもののうち実際に陽性だった割合。偽陽性を減らしたい場合に重視する。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'recall', jaName: '再現率', enName: 'Recall', description: '実際の陽性のうち正しく陽性と予測できた割合。偽陰性を減らしたい場合に重視する。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'f1-score', jaName: 'F1スコア', enName: 'F1 Score', description: '適合率と再現率の調和平均。両者のバランスを取った評価指標。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'confusion-matrix', jaName: '混同行列', enName: 'Confusion Matrix', description: '予測結果と実際のラベルの組み合わせを表にしたもの。TP/FP/FN/TNを可視化する。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'roc-curve', jaName: 'ROC曲線', enName: 'ROC Curve', description: '閾値を変化させたときの真陽性率と偽陽性率の関係を描いた曲線。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'auc', jaName: 'AUC', enName: 'Area Under the Curve', description: 'ROC曲線の下の面積。1に近いほど分類性能が高い。閾値に依存しない評価指標。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'log-loss', jaName: '対数損失', enName: 'Log Loss', description: '予測確率と正解ラベルの交差エントロピー。確率的予測の品質を評価する指標。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'mse', jaName: '平均二乗誤差', enName: 'Mean Squared Error', description: '予測値と実測値の差の二乗の平均。回帰タスクの代表的な評価指標。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'mae', jaName: '平均絶対誤差', enName: 'Mean Absolute Error', description: '予測値と実測値の差の絶対値の平均。外れ値に対してMSEより頑健。', sectionId: 'ml', subsectionId: 'ml-metrics' },
  { id: 'r-squared', jaName: '決定係数', enName: 'R-squared', description: '回帰モデルの当てはまりの良さを示す指標。1に近いほど説明力が高い。', sectionId: 'ml', subsectionId: 'ml-metrics' },
];
