import type { TermExamPoints } from '@/types/glossary';

/**
 * 深層学習の応用（DL応用）セクションの試験ポイント
 * E資格の出題傾向・頻出ポイントをまとめたデータ
 */
export const DL_APP_EXAM_POINTS: TermExamPoints[] = [
  // ========================================
  // 画像認識 (app-image)
  // ========================================
  {
    termId: 'lenet',
    points: [
      '畳み込み→プーリング→全結合の基本構成を問う問題が出る。各層の役割を説明できるようにする。',
      '手書き数字認識（MNIST）との関係が頻出。活性化関数にシグモイド/tanhを使用した点に注意。',
      'AlexNetとの違い（規模・活性化関数・正規化手法）を比較して整理しておく。',
    ],
  },
  {
    termId: 'alexnet',
    points: [
      'ImageNet 2012で優勝しディープラーニングブームの契機となった歴史的背景を問われる。',
      'ReLU活性化関数・Dropout・GPUによる並列学習・Local Response Normalizationの4つの特徴を覚える。',
      'VGGNetやGoogLeNetとの比較問題が頻出。層数やパラメータ数の違いを整理する。',
    ],
  },
  {
    termId: 'vggnet',
    points: [
      '3x3の小さなフィルタを重ねることで大きな受容野を得る仕組みが頻出。3x3を2層重ねると5x5相当になる。',
      'VGG16（13畳み込み+3全結合）とVGG19の違いを把握する。パラメータ数の大半は全結合層に集中。',
      'シンプルな設計ゆえに転移学習のバックボーンとしてよく使われる点を理解する。',
    ],
  },
  {
    termId: 'googlenet',
    points: [
      'Inceptionモジュール内の1x1・3x3・5x5畳み込みとプーリングの並列構造を図示できるようにする。',
      '1x1畳み込みによるチャネル数削減（次元削減）の役割が頻出。計算コスト削減の仕組みを理解する。',
      '補助分類器（Auxiliary Classifier）による勾配消失対策を問われることがある。',
    ],
  },
  {
    termId: 'resnet',
    points: [
      '残差接続 y = F(x) + x の式は必ず覚える。ショートカット接続で勾配消失を回避する仕組みが最頻出。',
      '「層を深くするほど精度が下がる劣化問題」をResNetが解決した背景を理解する。',
      'ResNet-50, ResNet-101などの数字は層数を表す。Bottleneckブロック（1x1→3x3→1x1）の構造を把握する。',
      'DenseNetとの比較（加算vs結合）が出題されやすい。',
    ],
    formula: 'y = F(x, {W_i}) + x',
  },
  {
    termId: 'densenet',
    points: [
      'ResNetが残差を「加算」するのに対しDenseNetは特徴マップを「結合(concatenation)」する違いが頻出。',
      '各層が全ての先行層の出力を入力として受け取る密結合構造を理解する。',
      'パラメータ効率が良い（特徴の再利用）点と、メモリ消費が大きい点の両面を把握する。',
    ],
  },
  {
    termId: 'efficientnet',
    points: [
      '深さ・幅・解像度の3つを複合的にスケーリングする「compound scaling」が最重要ポイント。',
      'スケーリング係数の関係式 depth=α^φ, width=β^φ, resolution=γ^φ (α・β²・γ²≈2) を理解する。',
      'NAS（Neural Architecture Search）でベースモデルを探索している点も出題される。',
    ],
    formula: 'depth: d=α^φ, width: w=β^φ, resolution: r=γ^φ (α·β²·γ²≈2)',
  },
  {
    termId: 'mobilenet',
    points: [
      'Depthwise Separable Convolution（Depthwise + Pointwise）の仕組みが最頻出。計算量削減の原理を理解する。',
      '通常の畳み込みとの計算量比較を計算できるようにする。計算量は約1/k²（kはカーネルサイズ）に削減。',
      'モバイル・エッジデバイスでの推論を前提とした軽量化アーキテクチャであることを把握する。',
    ],
    formula: '計算量比: 1/D_K² + 1/M （D_K: カーネルサイズ, M: 出力チャネル数）',
  },
  {
    termId: 'transfer-learning',
    points: [
      'ファインチューニングとの違いを明確にする。転移学習は特徴抽出器を固定して最終層のみ学習する場合を含む。',
      'ソースドメインとターゲットドメインの類似度によって戦略が変わる点が出題される。',
      '少量データでも高精度が得られる理由（事前学習で汎用的な特徴が学習済み）を説明できるようにする。',
    ],
  },
  {
    termId: 'fine-tuning',
    points: [
      '全層を学習するフルファインチューニングと一部の層のみ学習する部分ファインチューニングの違いを把握する。',
      '学習率を小さく設定する理由（事前学習の重みを大幅に壊さないため）が頻出。',
      '後方の層から段階的に解凍する手法（gradual unfreezing）が出題されることがある。',
    ],
  },
  {
    termId: 'image-classification',
    points: [
      'Top-1精度とTop-5精度の違いを問われる。ImageNetでは1000クラス分類がベンチマーク。',
      '損失関数にクロスエントロピー損失を使用する点、softmax出力との組み合わせを理解する。',
      'マルチラベル分類（1画像に複数クラス）ではシグモイド+バイナリクロスエントロピーを使う違いに注意。',
    ],
  },
  {
    termId: 'data-aug-image',
    points: [
      '代表的な手法（水平反転・ランダムクロップ・色変換・回転・Mixup・CutMix）を列挙できるようにする。',
      'テスト時にはデータ拡張を適用しない点に注意。ただしTTA（テスト時拡張）は例外。',
      '過学習抑制とデータ不足の補完が目的。正則化手法の一種として分類される。',
    ],
  },
  {
    termId: 'batch-norm-image',
    points: [
      'ミニバッチ内での正規化（平均0・分散1）の計算手順と、学習可能なスケール(γ)・シフト(β)パラメータを理解する。',
      '内部共変量シフトの軽減が目的。学習率を大きくでき、学習が高速化する。',
      '推論時はバッチ統計量ではなく移動平均を使う点が頻出。Dropoutとの併用に注意が必要。',
    ],
    formula: 'y = γ · (x - μ_B) / √(σ²_B + ε) + β',
  },
  {
    termId: 'skip-connection',
    points: [
      'ResNetの残差接続とU-Netのスキップ接続は目的が異なる。前者は勾配消失回避、後者は空間情報の保持。',
      '勾配がショートカットを通じて直接伝搬する仕組みが、深いネットワークの学習を可能にする理由を説明できるようにする。',
      'DenseNetの密結合やHighway Networkのゲート機構との違いを整理しておく。',
    ],
  },

  // ========================================
  // 物体検出 (app-detect)
  // ========================================
  {
    termId: 'rcnn',
    points: [
      'Selective Searchで領域提案→各領域をCNNで特徴抽出→SVMで分類、という3段階の処理を理解する。',
      '領域ごとにCNNを実行するため非常に遅い点が改善の動機。Fast R-CNN/Faster R-CNNとの速度比較が出題される。',
      'R-CNN→Fast R-CNN→Faster R-CNNの進化の流れを時系列で整理しておく。',
    ],
  },
  {
    termId: 'fast-rcnn',
    points: [
      '画像全体で1回だけCNN特徴抽出を行い、RoIプーリングで各領域の特徴を取り出す仕組みが改善点。',
      'マルチタスク損失（分類損失+回帰損失）でエンドツーエンドに学習できる点がR-CNNとの最大の違い。',
      '領域提案にはまだSelective Searchを使用しており、ここがボトルネックとなった点を理解する。',
    ],
  },
  {
    termId: 'faster-rcnn',
    points: [
      'Region Proposal Network（RPN）で領域提案もNNで行うことで完全なエンドツーエンド学習を実現した点が最重要。',
      'RPNがアンカーボックスを基準にobjectness scoreと位置補正を出力する仕組みを理解する。',
      '2段階検出器の代表例。精度は高いが1段階検出器（YOLO/SSD）より遅い点をトレードオフとして把握する。',
    ],
  },
  {
    termId: 'yolo',
    points: [
      '画像をグリッドに分割し、各グリッドセルがバウンディングボックスとクラス確率を同時に予測する仕組みが最重要。',
      '1段階検出器の代表。リアルタイム処理が可能だが、小さい物体や密集物体の検出が苦手な弱点がある。',
      'YOLO v1〜v8の進化を大まかに把握しておく。バージョンごとの主要改善点が出題される。',
    ],
  },
  {
    termId: 'ssd',
    points: [
      '複数の特徴マップスケールで同時にデフォルトボックスを用いて検出する仕組みを理解する。',
      'YOLOとの比較が頻出。SSDはマルチスケール検出により小さい物体にも対応できる利点がある。',
      '1段階検出器であり、速度と精度のバランスが良い点を把握する。',
    ],
  },
  {
    termId: 'feature-pyramid',
    points: [
      'ボトムアップ経路で抽出した特徴をトップダウン経路でアップサンプリングし、横方向接続で統合する構造を理解する。',
      'マルチスケール検出の精度を大幅に向上させた手法。Faster R-CNN等と組み合わせて使用される。',
      '各レベルの特徴マップが高解像度の位置情報と高レベルの意味情報の両方を持つ点がポイント。',
    ],
  },
  {
    termId: 'anchor-box',
    points: [
      '異なるアスペクト比・スケールの事前定義ボックスを複数用意し、各アンカーに対してオフセットとクラスを予測する仕組みが頻出。',
      'アンカーの設計（サイズ・比率の決め方）がデータセットに依存する点を理解する。K-meansクラスタリングで決定する方法も出題される。',
      'DETRのようなアンカーフリー手法との比較が近年出題されやすい。',
    ],
  },
  {
    termId: 'nms',
    points: [
      '処理手順を正確に覚える：(1)スコア最大のボックスを選択 (2)IoUが閾値以上の他のボックスを除去 (3)残りで繰り返し。',
      'IoU閾値の設定が検出結果に影響する。高すぎると重複検出、低すぎると近接物体の見逃しが起きる。',
      'Soft-NMS（スコアを抑制するがゼロにしない手法）との違いが出題されることがある。',
    ],
  },
  {
    termId: 'iou',
    points: [
      '計算式を正確に覚える。具体的な座標値からIoUを計算する問題が頻出。',
      '閾値0.5以上で「検出成功」とするのが一般的（PASCAL VOC基準）。COCO基準では複数閾値で評価する。',
      'NMSやmAPの計算で使われるため、他の概念との関連を理解しておく。',
    ],
    formula: 'IoU = |A ∩ B| / |A ∪ B| = |A ∩ B| / (|A| + |B| - |A ∩ B|)',
  },
  {
    termId: 'map-metric',
    points: [
      '各クラスでPrecision-Recallカーブを計算→APを算出→全クラスの平均がmAPという手順を理解する。',
      'PASCAL VOCのmAP（IoU=0.5）とCOCOのmAP（IoU=0.5:0.05:0.95の平均）の違いが頻出。',
      'Precision（適合率）とRecall（再現率）の定義との関連を正確に把握しておく。',
    ],
    formula: 'mAP = (1/|C|) Σ AP_c （C: クラス集合, AP: Average Precision）',
  },
  {
    termId: 'roi-pooling',
    points: [
      '任意サイズの領域を固定サイズ（例: 7x7）に変換する仕組みを理解する。量子化による情報損失がある。',
      'RoI Align（Mask R-CNNで導入）が双線形補間で量子化誤差を解消した改良点が頻出。',
      'Fast R-CNNでの役割（特徴マップの共有による高速化）を説明できるようにする。',
    ],
  },
  {
    termId: 'two-stage',
    points: [
      '第1段階（領域提案）と第2段階（分類・回帰）の2段階処理を行う。R-CNNファミリーが代表例。',
      '1段階検出器との比較が最頻出。精度は高いが速度が遅いトレードオフを理解する。',
      'Region Proposal Networkの導入で2段階でもリアルタイムに近づいた経緯を把握する。',
    ],
  },
  {
    termId: 'one-stage',
    points: [
      '領域提案を省略し、特徴マップから直接クラスと位置を予測する仕組みが特徴。YOLO・SSDが代表例。',
      '2段階検出器と比べて高速だが、特に初期のモデルでは小物体の検出精度が劣る傾向がある。',
      'FPN等の導入により精度が大幅に向上し、近年は2段階に匹敵する性能を達成している。',
    ],
  },
  {
    termId: 'detr',
    points: [
      'Transformerのエンコーダ・デコーダ構造を物体検出に適用した点が最重要。アンカーやNMSが不要。',
      'Object Queryの概念（学習可能な問い合わせベクトル）と二部マッチング損失を理解する。',
      '学習の収束が遅い課題がある。Deformable DETRなどの改良手法との関係を把握する。',
    ],
  },

  // ========================================
  // セグメンテーション (app-seg)
  // ========================================
  {
    termId: 'semantic-seg',
    points: [
      '各ピクセルにクラスラベルを付与するが、同じクラスの個々の物体は区別しない点が最重要。',
      'インスタンスセグメンテーション・パノプティックセグメンテーションとの違いを表で整理しておく。',
      '評価指標のmIoU（Mean Intersection over Union）の計算方法を理解する。',
    ],
  },
  {
    termId: 'instance-seg',
    points: [
      'セマンティックセグメンテーションとの違い：同じクラスでも個々の物体を区別できる点が重要。',
      'Mask R-CNNが代表手法。物体検出+ピクセル単位のマスク予測の組み合わせを理解する。',
      '背景ピクセルには対応しない（thingsのみ対象）点がパノプティックとの違い。',
    ],
  },
  {
    termId: 'panoptic-seg',
    points: [
      'セマンティック（stuff: 空・道路等）とインスタンス（things: 車・人等）を統合したタスクであることが最重要。',
      'Panoptic Quality (PQ) = SQ × RQ の評価指標を理解する。',
      '全ピクセルにラベルを付与し、かつthingsは個体ごとに区別する点を把握する。',
    ],
    formula: 'PQ = SQ × RQ = (Σ IoU(p,g) / |TP|) × (|TP| / (|TP| + |FP|/2 + |FN|/2))',
  },
  {
    termId: 'fcn',
    points: [
      '全結合層を1x1畳み込みに置き換えることで任意サイズの入力に対応可能にした点が最重要。',
      'FCN-32s, FCN-16s, FCN-8sの違い（アップサンプリングの段階数）を理解する。数字が小さいほど高精度。',
      'セグメンテーション用CNNの原型であり、後続のU-Net・DeepLab等への発展を把握する。',
    ],
  },
  {
    termId: 'unet',
    points: [
      'エンコーダ（収縮パス）とデコーダ（拡張パス）のU字型構造とスキップ接続が最重要ポイント。',
      '医用画像セグメンテーションで広く使われる。少量データでも有効な点が特徴。',
      'スキップ接続により低レベルの空間情報と高レベルの意味情報を統合する仕組みを理解する。',
    ],
  },
  {
    termId: 'deeplab',
    points: [
      'Atrous Convolution（Dilated Convolution）で解像度を保ちながら受容野を拡大する仕組みが最重要。',
      'ASPP（Atrous Spatial Pyramid Pooling）で複数のdilation rateを並列適用するマルチスケール処理を理解する。',
      'CRF（条件付き確率場）による後処理で境界を精緻化する手法（DeepLab v1/v2）も出題される。',
    ],
  },
  {
    termId: 'pspnet',
    points: [
      'ピラミッドプーリングモジュールで1x1, 2x2, 3x3, 6x6の複数スケールでグローバルな文脈情報を統合する仕組みを理解する。',
      'DeepLabのASPPとの比較が出題される。PSPNetはプーリング、ASPPはAtrous Convolutionでマルチスケールを実現。',
      'グローバルコンテキスト情報の活用により、局所的な誤認識を低減する点がポイント。',
    ],
  },
  {
    termId: 'mask-rcnn',
    points: [
      'Faster R-CNNにマスク予測ブランチを追加した構造が最重要。分類・回帰・マスクの3タスクを同時学習。',
      'RoI Align（双線形補間）をRoI Poolingの代わりに使用し、量子化誤差を解消した点が頻出。',
      'インスタンスセグメンテーション・姿勢推定・キーポイント検出にも応用できる汎用性を把握する。',
    ],
  },
  {
    termId: 'atrous-conv',
    points: [
      'フィルタの間隔（dilation rate）を広げることで、パラメータ数を増やさずに受容野を拡大する仕組みが最重要。',
      'dilation rate=1は通常の畳み込みと同じ。rate=2なら1ピクセルおきにサンプリングする。',
      'プーリングによる解像度低下を避けつつ広い文脈を捉えられる利点を理解する。',
    ],
    formula: '受容野 = k + (k-1)(r-1) （k: カーネルサイズ, r: dilation rate）',
  },
  {
    termId: 'segformer',
    points: [
      'TransformerベースのエンコーダとシンプルなMLPデコーダの組み合わせが特徴。位置エンコーディングが不要。',
      '階層的なTransformerエンコーダでマルチスケール特徴を抽出する仕組みを理解する。',
      'CNN系のセグメンテーションモデルとの比較（グローバルな文脈把握力の違い）が出題される。',
    ],
  },

  // ========================================
  // NLP (app-nlp)
  // ========================================
  {
    termId: 'word2vec',
    points: [
      'CBOW（周辺語→中心語を予測）とSkip-gram（中心語→周辺語を予測）の2手法の違いが最頻出。',
      '「king - man + woman ≈ queen」のような単語ベクトルの加減算による意味的関係が問われる。',
      'Negative Samplingの役割（softmaxの計算コスト削減）を理解する。',
    ],
  },
  {
    termId: 'glove',
    points: [
      '単語の共起行列のログを目的関数に組み込む手法。Word2Vecが局所的な文脈を使うのに対し、大域的な統計情報を活用する。',
      '目的関数は重み付き最小二乗法。高頻度共起ペアに引きずられないよう重み関数でクリップする。',
      'Word2Vecとの比較（局所 vs 大域、予測型 vs 計数型）が出題されやすい。',
    ],
    formula: 'J = Σ f(X_ij)(w_i^T w̃_j + b_i + b̃_j - log X_ij)²',
  },
  {
    termId: 'fasttext',
    points: [
      '単語をサブワード（文字n-gram）に分解して埋め込みを学習する点がWord2Vecとの最大の違い。',
      '未知語（OOV: Out of Vocabulary）にもサブワードの合成で対応できる利点が頻出。',
      '形態素が豊富な言語（日本語・トルコ語等）で効果が高い点を把握する。',
    ],
  },
  {
    termId: 'word-embedding',
    points: [
      'One-hotベクトル（疎・高次元）から密な低次元ベクトルへの変換が基本概念。次元の呪いの回避が目的。',
      '分布仮説（「似た文脈に現れる単語は似た意味を持つ」）が理論的根拠として出題される。',
      '文脈非依存型（Word2Vec等）と文脈依存型（BERT等）の違いを理解する。',
    ],
  },
  {
    termId: 'tokenization',
    points: [
      '単語レベル・サブワードレベル・文字レベルの3つの粒度の違いとトレードオフを理解する。',
      'サブワードトークナイゼーション（BPE, SentencePiece）が現在の主流。未知語問題を解決する。',
      '日本語は形態素解析（MeCab等）が必要な点が英語との違いとして出題される。',
    ],
  },
  {
    termId: 'bpe',
    points: [
      '最頻出の文字ペアを統合していくボトムアップの手法。マージ操作の回数が語彙サイズを決定する。',
      '具体的なマージ手順を追跡する問題が出る。例: "l o w" → "lo w" → "low" のような手順。',
      'GPTシリーズで採用されている点を把握する。SentencePieceとの関係も理解する。',
    ],
  },
  {
    termId: 'sentencepiece',
    points: [
      '事前のトークナイゼーション（空白分割等）が不要で、生のテキストから直接サブワードを学習する点が特徴。',
      'BPEモデルとUnigramモデルの両方をサポートする。Unigramは確率ベースで最適な分割を選択。',
      '言語に依存しないため、多言語モデル（mBERT等）で広く使用される点を把握する。',
    ],
  },
  {
    termId: 'language-model',
    points: [
      '次の単語の確率を予測する自己回帰型と、マスクされた単語を予測するマスク言語モデルの違いが頻出。',
      'パープレキシティ（perplexity）が評価指標。低いほど良い。確率の逆数の幾何平均として計算。',
      'GPT系（自己回帰）とBERT系（マスク言語モデル）の違いを整理しておく。',
    ],
    formula: 'PPL = exp(-(1/N) Σ log P(w_i | w_1,...,w_{i-1}))',
  },
  {
    termId: 'ner',
    points: [
      'BIO/IOBタグ付けスキーム（B-PER, I-PER, O等）の仕組みが頻出。系列ラベリングタスクとして解く。',
      'CRF層をBiLSTMやBERTの上に載せて系列の整合性を保つ手法が出題される。',
      '人名(PER)・地名(LOC)・組織名(ORG)・日時(DATE)等の代表的なエンティティ型を覚える。',
    ],
  },
  {
    termId: 'sentiment',
    points: [
      '文書レベル・文レベル・アスペクトレベルの3つの粒度の違いを理解する。',
      '事前学習済みモデル（BERT等）のファインチューニングが現在の主流手法。',
      'テキスト分類の一種であり、損失関数にクロスエントロピーを使う点を把握する。',
    ],
  },
  {
    termId: 'machine-translation',
    points: [
      'Seq2Seq（エンコーダ・デコーダ）モデルが基盤。Attention機構の導入で長文の翻訳品質が向上した経緯を理解する。',
      'Transformer（Attention Is All You Need）が機械翻訳で提案された歴史的背景が出題される。',
      'BLEU（Bilingual Evaluation Understudy）スコアが評価指標として頻出。n-gramの一致率に基づく。',
    ],
  },
  {
    termId: 'qa',
    points: [
      '抽出型QA（文書中のスパンを特定）と生成型QA（回答を生成）の違いが頻出。',
      'BERTベースの抽出型QAでは、開始位置と終了位置の確率を出力する仕組みを理解する。',
      'SQuADデータセットでの評価指標（Exact Match, F1スコア）を把握する。',
    ],
  },
  {
    termId: 'text-classification',
    points: [
      'スパム検出・トピック分類・感情分析等が代表的な応用。最終層にsoftmax（多クラス）またはsigmoid（マルチラベル）を使用。',
      'BERTの[CLS]トークンの出力を分類に使う手法が現在の主流として出題される。',
      '従来手法（Bag of Words + ロジスティック回帰）との比較が出ることがある。',
    ],
  },
  {
    termId: 'pretrained-lm',
    points: [
      'BERT（マスク言語モデル+次文予測）とGPT（自己回帰言語モデル）の事前学習タスクの違いが最頻出。',
      '「事前学習→ファインチューニング」のパラダイムがNLP分野を革新した流れを理解する。',
      'モデルサイズ・学習データ量・計算量のスケーリング則が性能に影響する点も出題される。',
    ],
  },
  {
    termId: 'prompt-engineering',
    points: [
      'Zero-shot・Few-shot・Chain-of-Thought（CoT）プロンプティングの違いが出題される。',
      'モデルのパラメータを更新せずに出力を制御できる点がファインチューニングとの最大の違い。',
      '具体的な指示・例示・出力形式の指定が効果的なプロンプト設計の要素であることを把握する。',
    ],
  },
  {
    termId: 'instruction-tuning',
    points: [
      '多様なタスクを指示文形式でファインチューニングし、未見のタスクにも汎化する能力を獲得する手法。',
      'RLHFとの関係：Instruction Tuningで指示に従う能力を付け、RLHFで人間の好みに合わせるという2段階を理解する。',
      'FLAN、InstructGPTなどの代表的なモデルを把握する。',
    ],
  },

  // ========================================
  // 生成モデル (app-gen)
  // ========================================
  {
    termId: 'gan',
    points: [
      '生成器G（ノイズ→偽データ）と識別器D（本物/偽物を判定）のミニマックスゲームとして定式化される点が最重要。',
      'ナッシュ均衡に収束する理論と、実際には学習が不安定になりやすい問題（モード崩壊等）を理解する。',
      'VAEとの比較（明示的な尤度計算の有無、生成画像の鮮明さの違い）が頻出。',
    ],
    formula: 'min_G max_D V(D,G) = E[log D(x)] + E[log(1 - D(G(z)))]',
  },
  {
    termId: 'vae',
    points: [
      '損失関数が再構成損失（データの復元精度）とKLダイバージェンス（事前分布への正則化）の和である点が最重要。',
      '再パラメータ化トリック（z = μ + σ⊙ε）により確率的サンプリングを微分可能にする仕組みが頻出。',
      'GANとの比較：VAEは明示的に尤度を最大化するが、生成画像がぼやけやすい傾向がある。',
    ],
    formula: 'L = -E_q[log p(x|z)] + KL(q(z|x) || p(z))',
  },
  {
    termId: 'autoencoder',
    points: [
      'エンコーダ（入力→潜在表現）とデコーダ（潜在表現→再構成）の構造を理解する。ボトルネック層で次元削減。',
      'PCA（主成分分析）との関係：線形のオートエンコーダはPCAと等価になる点が出題される。',
      'Denoising Autoencoder、Sparse Autoencoder等の変種の目的と違いを把握する。',
    ],
  },
  {
    termId: 'dcgan',
    points: [
      '安定した学習のための設計指針が重要：プーリング→ストライド畳み込み、全結合層の排除、Batch Normalizationの使用。',
      '生成器はTransposed Convolution（逆畳み込み）でアップサンプリングする仕組みを理解する。',
      'GANの学習安定化の先駆的研究として、後続のWGAN等の改良手法への流れを把握する。',
    ],
  },
  {
    termId: 'wgan',
    points: [
      'JS divergenceの代わりにWasserstein距離（Earth Mover\'s Distance）を使用する点が最重要。',
      '識別器をCritic（実数値を出力）に変更し、Lipschitz制約を課す。Weight Clippingまたは勾配ペナルティ（WGAN-GP）で実現。',
      'モード崩壊の改善と学習の安定性向上が主な利点。損失値が生成品質と相関する点も重要。',
    ],
    formula: 'W(P_r, P_g) = sup_{||f||_L≤1} E[f(x)] - E[f(G(z))]',
  },
  {
    termId: 'stylegan',
    points: [
      'Mapping Network（潜在変数zを中間空間wに変換）とAdaIN（Adaptive Instance Normalization）によるスタイル注入が特徴。',
      '粗い特徴（姿勢・顔の形）から細かい特徴（色・テクスチャ）まで階層的にスタイルを制御できる仕組みを理解する。',
      'Progressive Growing（低解像度から段階的に高解像度化）の学習戦略も出題される。',
    ],
  },
  {
    termId: 'conditional-gan',
    points: [
      '生成器と識別器の両方に条件情報（クラスラベル等）を入力する仕組みが基本。',
      '無条件GANとの違い：生成する出力を制御できる点。クラスラベルを指定して特定のカテゴリの画像を生成可能。',
      'Pix2PixやCycleGANも条件付きGANの発展形として位置づけられる。',
    ],
  },
  {
    termId: 'cycle-gan',
    points: [
      'ペアデータが不要な画像変換（unpaired image-to-image translation）が最大の特徴。',
      'サイクル整合性損失: G(F(y))≈y, F(G(x))≈x で変換の一貫性を保証する仕組みが最重要。',
      'Pix2Pixとの比較（ペアデータの要否）が頻出。馬↔シマウマ等の変換例が典型。',
    ],
    formula: 'L_cyc = E[||F(G(x)) - x||₁] + E[||G(F(y)) - y||₁]',
  },
  {
    termId: 'pix2pix',
    points: [
      'ペア画像（入力→出力の対応付き）で画像変換を学習する条件付きGAN。L1損失とAdversarial損失を併用。',
      'PatchGAN識別器（画像全体ではなくパッチ単位で真偽判定）の仕組みが出題される。',
      'CycleGANとの比較（ペアデータが必要 vs 不要）を整理しておく。',
    ],
    formula: 'L = L_GAN + λ · L_L1  （λはL1損失の重み）',
  },
  {
    termId: 'diffusion-model',
    points: [
      '前方過程（段階的にノイズを加える）と逆過程（ノイズを除去して生成）の2つの過程が基本概念。',
      'GANと比較して学習が安定し、モード崩壊がない利点がある。一方で生成速度が遅い欠点がある。',
      'スコアマッチング・確率微分方程式（SDE）との理論的関係が出題されることがある。',
    ],
  },
  {
    termId: 'ddpm',
    points: [
      '前方過程でT段階のガウスノイズを加え、逆過程でノイズを予測して除去する手法。',
      '各ステップでのノイズスケジュール（β_t）の設定が重要。線形スケジュールが基本。',
      '損失関数は各ステップで加えたノイズとモデルの予測ノイズのMSE。',
    ],
    formula: 'L_simple = E_{t,x_0,ε}[||ε - ε_θ(x_t, t)||²]',
  },
  {
    termId: 'stable-diffusion',
    points: [
      '画素空間ではなく潜在空間で拡散過程を行うLatent Diffusion Modelが基盤技術。計算効率が大幅に向上。',
      'VAEエンコーダ（画像→潜在表現）、U-Net（ノイズ除去）、テキストエンコーダ（CLIP）の3つの構成要素を理解する。',
      'Classifier-free Guidanceによるテキスト条件付き生成の仕組みが出題される。',
    ],
  },
  {
    termId: 'flow-based',
    points: [
      '可逆変換の系列で複雑な分布を単純な分布（ガウス分布等）に変換する。変数変換の公式で正確な尤度計算が可能。',
      'GANやVAEとの比較：正確な尤度計算が可能だが、可逆性の制約によりモデル設計が限定される。',
      'NICE、RealNVP、Glow等の代表的なモデルを把握する。',
    ],
    formula: 'log p(x) = log p(z) + Σ log |det(∂f_i/∂z_{i-1})|',
  },
  {
    termId: 'latent-space',
    points: [
      'データの本質的な特徴を低次元で表現する空間。連続的な空間では近い点が類似したデータに対応する。',
      'VAEでは潜在空間が正規分布に正則化されるため、滑らかな補間が可能な点が重要。',
      'GANの潜在空間での線形補間（画像の滑らかな変化）が出題されることがある。',
    ],
  },
  {
    termId: 'reparameterization',
    points: [
      'z = μ + σ⊙ε（εは標準正規分布からサンプリング）により、確率的操作を微分可能にする手法。',
      'VAEの学習でバックプロパゲーションを可能にするために不可欠な技術であることが最重要。',
      'サンプリング操作が微分不可能な問題を、確定的な変換+外部ノイズに分離して解決する発想を理解する。',
    ],
    formula: 'z = μ + σ ⊙ ε,  ε ~ N(0, I)',
  },
  {
    termId: 'mode-collapse',
    points: [
      '生成器が多様性を失い、少数のパターンしか生成しなくなる現象。GANの主要な課題。',
      '対策としてWGAN（Wasserstein距離）、ミニバッチ識別、Unrolled GANなどがある点を把握する。',
      'VAEや拡散モデルではモード崩壊が起きにくい理由（明示的な尤度最大化）も理解する。',
    ],
  },

  // ========================================
  // 深層強化学習 (app-rl)
  // ========================================
  {
    termId: 'mdp',
    points: [
      '(S, A, P, R, γ) の5つ組で定義される。S:状態集合、A:行動集合、P:遷移確率、R:報酬関数、γ:割引率。',
      'マルコフ性（次の状態は現在の状態と行動のみに依存し、過去の履歴に依存しない）が最重要。',
      'ベルマン方程式との関係を理解する。MDPの最適解はベルマン最適方程式で特徴づけられる。',
    ],
  },
  {
    termId: 'q-learning',
    points: [
      'Q値の更新式を正確に覚える。off-policy（行動方策と学習対象の方策が異なる）であることが重要。',
      'ε-greedy方策（確率εでランダム行動、1-εで貪欲行動）による探索と活用のバランスを理解する。',
      'SARSAとの違い（Q学習はmax、SARSAは実際の行動のQ値を使用）が頻出。',
    ],
    formula: 'Q(s,a) ← Q(s,a) + α[r + γ max_a\' Q(s\',a\') - Q(s,a)]',
  },
  {
    termId: 'dqn',
    points: [
      '経験再生（Experience Replay）とターゲットネットワーク（定期的に同期する別のネットワーク）の2つの安定化技術が最重要。',
      'Q学習のQ値テーブルをニューラルネットワークで近似した点がQ学習との違い。',
      'Atariゲームで人間を超えた成果が画期的。Double DQN、Dueling DQN等の改良手法も把握する。',
    ],
  },
  {
    termId: 'policy-gradient',
    points: [
      '方策を直接パラメータ化し、期待累積報酬の勾配で方策を更新する手法。',
      'REINFORCE（モンテカルロ方策勾配法）の更新則を理解する。ベースラインによる分散低減が重要。',
      '価値ベース（Q学習等）との違い：連続行動空間に自然に対応でき、確率的方策を直接学習できる。',
    ],
    formula: '∇_θ J(θ) = E[Σ_t ∇_θ log π_θ(a_t|s_t) · G_t]',
  },
  {
    termId: 'actor-critic',
    points: [
      'Actor（方策ネットワーク）が行動を選択し、Critic（価値ネットワーク）が行動を評価する2つのネットワーク構成が最重要。',
      '方策勾配法の高分散問題をCriticによるベースラインで緩和する仕組みを理解する。',
      'Advantage関数 A(s,a) = Q(s,a) - V(s) を使うAdvantage Actor-Criticが基本形。',
    ],
    formula: 'A(s,a) = Q(s,a) - V(s)  （Advantage関数）',
  },
  {
    termId: 'a3c',
    points: [
      '複数のワーカーが並列に異なる環境で学習し、グローバルなパラメータを非同期に更新する仕組みが特徴。',
      '経験再生が不要（並列環境からの多様な経験で代替）な点がDQNとの違い。',
      'Advantage Actor-Criticをベースとし、非同期更新で学習を高速化した手法であることを把握する。',
    ],
  },
  {
    termId: 'ppo',
    points: [
      'クリッピングされた目的関数で方策の更新幅を制限し、学習の安定性を確保する手法が最重要。',
      'TRPO（Trust Region Policy Optimization）の近似版として、実装が簡単かつ性能が高い点が特徴。',
      'RLHFでの方策最適化にPPOが使用される点がLLM関連で頻出。',
    ],
    formula: 'L^CLIP = E[min(r_t(θ)Â_t, clip(r_t(θ), 1-ε, 1+ε)Â_t)]',
  },
  {
    termId: 'reward',
    points: [
      '即時報酬と累積報酬（リターン）の違いを理解する。割引累積報酬 G_t = Σ γ^k r_{t+k+1} が最適化対象。',
      '報酬の設計（報酬シェーピング）が学習の効率と結果に大きく影響する点が出題される。',
      'スパース報酬（ゴール時のみ報酬）と密な報酬（毎ステップ報酬）のトレードオフを理解する。',
    ],
    formula: 'G_t = Σ_{k=0}^{∞} γ^k r_{t+k+1}  （γ: 割引率）',
  },
  {
    termId: 'value-function',
    points: [
      '状態価値関数V(s)と行動価値関数Q(s,a)の違いが最頻出。V(s)は状態の価値、Q(s,a)は状態行動ペアの価値。',
      'ベルマン方程式（V(s) = E[r + γV(s\')]）で再帰的に定義される点を理解する。',
      '最適価値関数と最適方策の関係を把握する。最適方策はQ*(s,a)を最大化する行動を選択する。',
    ],
    formula: 'V^π(s) = E_π[Σ γ^k r_{t+k+1} | s_t=s],  Q^π(s,a) = E_π[Σ γ^k r_{t+k+1} | s_t=s, a_t=a]',
  },
  {
    termId: 'policy',
    points: [
      '確定的方策 a = μ(s) と確率的方策 π(a|s) の違いを理解する。',
      '方策ベース手法と価値ベース手法の比較が頻出。方策ベースは連続行動空間に適する。',
      'greedy方策とε-greedy方策の違い、探索と活用のバランスとの関係を把握する。',
    ],
  },
  {
    termId: 'exploration-exploitation',
    points: [
      '探索（未知の行動を試して情報を得る）と活用（現在の最適行動で報酬を最大化する）のジレンマが基本概念。',
      'ε-greedy、UCB（Upper Confidence Bound）、ボルツマン探索等の代表的な探索戦略を把握する。',
      '探索が不十分だと局所最適に陥り、過剰だと収束が遅くなるトレードオフを理解する。',
    ],
  },
  {
    termId: 'experience-replay',
    points: [
      '過去の遷移(s, a, r, s\')をバッファに保存し、ランダムにサンプリングして学習する仕組みが基本。',
      'データの時間的相関を破壊してi.i.d.に近づけることで学習を安定化させる効果が最重要。',
      'Prioritized Experience Replay（TD誤差が大きい経験を優先的にサンプリング）も出題される。',
    ],
  },
  {
    termId: 'td-learning',
    points: [
      'TD誤差 δ = r + γV(s\') - V(s) を用いてブートストラップで価値を更新する手法。',
      'モンテカルロ法（エピソード終了まで待つ）との違い：TD法は1ステップごとに更新でき、バイアスはあるが分散が小さい。',
      'TD(0)、TD(λ)の違いとλの役割（MC法とTD法のバランス）を理解する。',
    ],
    formula: 'V(s) ← V(s) + α[r + γV(s\') - V(s)]  （δ = r + γV(s\') - V(s): TD誤差）',
  },
  {
    termId: 'rlhf',
    points: [
      '3段階のプロセスを理解する：(1)教師ありファインチューニング (2)報酬モデルの学習 (3)PPOによる方策最適化。',
      '人間の選好データ（AよりBが良い等のランキング）から報酬モデルを学習する仕組みが最重要。',
      'ChatGPT/GPT-4の学習に使用された技術として出題頻度が高い。DPO（Direct Preference Optimization）との比較も把握する。',
    ],
  },

  // ========================================
  // 様々な学習方法 (app-methods)
  // ========================================
  {
    termId: 'meta-learning',
    points: [
      '「学習の仕方を学習する」という概念が基本。タスク分布からの汎化が目的。',
      'MAML（Model-Agnostic Meta-Learning）が代表手法。少数の勾配更新で新タスクに適応できる初期パラメータを学習する。',
      'Few-shot学習との関係を理解する。メタ学習はFew-shot学習を実現するための枠組みの一つ。',
    ],
  },
  {
    termId: 'few-shot',
    points: [
      'N-way K-shot（N個のクラスから各K個のサンプルで学習）の設定が基本。5-way 1-shotや5-way 5-shotが代表的。',
      'サポートセット（学習用の少数例）とクエリセット（評価用データ）の構成を理解する。',
      'Prototypical Networks（各クラスのプロトタイプとの距離で分類）が代表的な手法。',
    ],
  },
  {
    termId: 'zero-shot',
    points: [
      '訓練時に見たことがないクラスを認識する能力。クラスの属性情報やテキスト記述等の補助情報を利用する。',
      'CLIPのようなビジョン言語モデルでのゼロショット分類が近年頻出。テキスト記述で新クラスを定義できる。',
      'Few-shot学習との違い：Zero-shotは例示なし、Few-shotは少数の例示あり。',
    ],
  },
  {
    termId: 'contrastive-learning',
    points: [
      '正例ペア（同じデータの異なる拡張）を近づけ、負例ペア（異なるデータ）を遠ざける学習目的が基本。',
      '自己教師あり学習（ラベルなしでの表現学習）の代表的手法として出題される。',
      'InfoNCE損失が代表的な損失関数。温度パラメータτの役割を理解する。',
    ],
    formula: 'L = -log(exp(sim(z_i, z_j)/τ) / Σ_k exp(sim(z_i, z_k)/τ))',
  },
  {
    termId: 'simclr',
    points: [
      'データ拡張で正例ペアを生成し、同一バッチ内の他のサンプルを負例として使う仕組みが特徴。',
      '大きなバッチサイズが性能に重要（負例の数が多いほど良い）な点がMoCoとの違い。',
      '非線形射影ヘッド（MLP）がコントラスティブ損失の前に重要な役割を果たす点を理解する。',
    ],
  },
  {
    termId: 'moco',
    points: [
      'モメンタムエンコーダとキュー（負例のプール）を使い、大きなバッチサイズなしに多数の負例を確保する手法。',
      'SimCLRとの比較が頻出。MoCoはメモリ効率が良く、小さなバッチでも学習可能。',
      'モメンタム更新 θ_k ← m·θ_k + (1-m)·θ_q の式と、mが1に近い値（0.999等）である理由を理解する。',
    ],
    formula: 'θ_k ← m · θ_k + (1-m) · θ_q  （m: モメンタム係数, 通常0.999）',
  },
  {
    termId: 'multi-task',
    points: [
      '複数のタスクで共有表現を学習することで汎化性能が向上する仕組みが基本概念。',
      'ハードパラメータ共有（下位層を共有）とソフトパラメータ共有（正則化で近づける）の違いを理解する。',
      'タスク間の相性が悪いと性能が低下する「負の転移」の問題を把握する。',
    ],
  },
  {
    termId: 'curriculum-learning',
    points: [
      '簡単なサンプルから段階的に難しいサンプルを導入する学習戦略。人間の学習過程に着想を得ている。',
      'サンプルの難易度の定義方法（損失値、予測確信度等）が出題される。',
      'Self-paced Learning（モデル自身が難易度を判断して学習順序を決める手法）との関係を把握する。',
    ],
  },
  {
    termId: 'active-learning',
    points: [
      'モデルが最も情報価値の高いサンプルを選んでラベル付けを依頼する仕組みが基本。アノテーションコストの削減が目的。',
      '不確実性サンプリング（予測が最も不確実なサンプルを選択）が代表的な戦略。',
      'プールベース・ストリームベース・メンバーシップクエリの3つのシナリオを把握する。',
    ],
  },
  {
    termId: 'federated-learning',
    points: [
      'データを中央に集約せず、各デバイスでローカルに学習し勾配（またはモデル更新）のみを共有する仕組みが最重要。',
      'プライバシー保護が主な動機。医療データや個人データの活用場面で出題される。',
      'Non-IIDデータ（各デバイスのデータ分布が異なる）での学習が課題であることを理解する。',
    ],
  },
  {
    termId: 'graph-nn',
    points: [
      'グラフ構造（ノード・エッジ）のデータを処理するNN。ソーシャルネットワーク・分子構造・推薦システム等が応用先。',
      'メッセージパッシング（隣接ノードの情報を集約して更新）の仕組みが基本操作。',
      'GCN、GAT（Graph Attention Network）、GraphSAGE等の代表的な手法を把握する。',
    ],
  },
  {
    termId: 'gcn',
    points: [
      'グラフ上の畳み込みをスペクトル領域で定義し、近似（1次チェビシェフ多項式）で効率的に計算する仕組みが基本。',
      '隣接行列と特徴行列を用いた伝搬式 H^(l+1) = σ(D̃^(-1/2)ÃD̃^(-1/2)H^(l)W^(l)) を理解する。',
      'Over-smoothing問題（層を深くすると全ノードの表現が似てしまう）が主な課題。',
    ],
    formula: 'H^(l+1) = σ(D̃^(-1/2) Ã D̃^(-1/2) H^(l) W^(l))  （Ã = A + I）',
  },
  {
    termId: 'attention-mechanism',
    points: [
      'Query・Key・Valueの3要素による重み付き和の仕組みが最重要。Q・K・Vの役割を説明できるようにする。',
      'Scaled Dot-Product Attentionの計算式を覚える。スケーリング（√d_k で割る）の理由も理解する。',
      'Seq2Seqでの導入経緯からTransformerへの発展を時系列で整理しておく。',
    ],
    formula: 'Attention(Q,K,V) = softmax(QK^T / √d_k) V',
  },
  {
    termId: 'neural-architecture-search',
    points: [
      '探索空間（候補となるアーキテクチャ）・探索戦略（強化学習・進化的手法等）・性能評価の3要素を理解する。',
      '計算コストが非常に大きい点が課題。DARTS（微分可能NAS）による効率化が重要な改良。',
      'EfficientNetのベースモデルがNASで探索された点との関連を把握する。',
    ],
  },
  {
    termId: 'continual-learning',
    points: [
      '破滅的忘却（新タスク学習時に旧タスクの知識を忘れる問題）が最大の課題。',
      '対策の3分類を覚える：正則化ベース（EWC等）、リプレイベース（過去データの再学習）、構造ベース（タスクごとにパラメータ分離）。',
      '転移学習やマルチタスク学習との違い：継続学習は逐次的にタスクが到来する点が特徴。',
    ],
  },
  {
    termId: 'self-training',
    points: [
      'モデルの高確信度予測を擬似ラベルとしてラベルなしデータに付与し、再学習する半教師あり学習手法。',
      '確信度の閾値設定が重要。低すぎると誤ラベルが混入し、高すぎるとデータが少なくなる。',
      '教師あり学習と自己教師あり学習の中間的な位置づけ。Pseudo Labelingとも呼ばれる。',
    ],
  },

  // ========================================
  // 説明性 (app-xai)
  // ========================================
  {
    termId: 'grad-cam',
    points: [
      '最終畳み込み層の勾配をグローバル平均プーリングして重みを算出し、特徴マップの重み付き和でヒートマップを生成する仕組み。',
      'CNNの判断根拠を可視化する手法として最も出題頻度が高い。クラスごとに異なるヒートマップが得られる点を理解する。',
      'Grad-CAM++やScore-CAM等の改良手法との違いも把握しておく。',
    ],
    formula: 'L^c = ReLU(Σ_k α^c_k A^k),  α^c_k = (1/Z)Σ_i Σ_j ∂y^c/∂A^k_{ij}',
  },
  {
    termId: 'lime',
    points: [
      '説明したいインスタンスの周辺で摂動データを生成し、局所的に線形モデルで近似する手法が基本。',
      'モデルに依存しない（model-agnostic）点が最大の特徴。どんなブラックボックスモデルにも適用可能。',
      'SHAPとの比較が頻出。LIMEは局所的近似、SHAPはシャープレイ値に基づく理論的に厳密な手法。',
    ],
  },
  {
    termId: 'shap',
    points: [
      'ゲーム理論のシャープレイ値を機械学習の特徴量寄与度に応用した手法。各特徴量の限界貢献度を計算する。',
      '4つの性質（効率性・対称性・ダミー・加法性）を満たす唯一の手法であることが理論的強み。',
      'KernelSHAP（モデル非依存）とTreeSHAP（木モデル特化で高速）の違いを把握する。',
    ],
    formula: 'φ_i = Σ_{S⊆N\\{i}} (|S|!(|N|-|S|-1)!/|N|!) [f(S∪{i}) - f(S)]',
  },
  {
    termId: 'saliency-map',
    points: [
      '入力画像の各ピクセルに対する出力の勾配（∂y/∂x）を計算して可視化する最もシンプルな手法。',
      '勾配の絶対値やSmoothGrad（ノイズを加えた入力の勾配を平均化）で可視化品質を向上させる。',
      'Grad-CAMとの違い：Saliency Mapは入力レベル、Grad-CAMは特徴マップレベルの可視化。',
    ],
  },
  {
    termId: 'attention-viz',
    points: [
      'Transformerの各ヘッド・各層のAttention重みをヒートマップとして表示し、トークン間の関係を理解する手法。',
      'Attention重みが必ずしもモデルの判断根拠を正確に反映するとは限らない点に注意。',
      'BERTやGPTなどの大規模言語モデルのデバッグ・解析に使用される。',
    ],
  },
  {
    termId: 'feature-importance',
    points: [
      '各特徴量を除外/置換した場合のモデル性能の変化で重要度を測るPermutation Importanceが代表的手法。',
      'SHAPの特徴量寄与度との違い：Feature Importanceはグローバルな指標、SHAPはインスタンスごとの寄与度。',
      'ランダムフォレストのGini重要度等、モデル固有の手法もあることを把握する。',
    ],
  },
  {
    termId: 'counterfactual',
    points: [
      '「この入力のどこを変えれば予測が変わるか」を示す説明手法。因果推論的なアプローチ。',
      '実現可能性（現実的に起こり得る変更か）とスパース性（最小限の変更か）が良い反実仮想説明の基準。',
      '意思決定の改善提案（例：融資を受けるには年収をX万円上げればよい）に活用される実用例を理解する。',
    ],
  },
  {
    termId: 'interpretability',
    points: [
      '事前解釈性（モデル自体が解釈可能：決定木、線形モデル）と事後解釈性（ブラックボックスに説明を後付け：LIME、SHAP）の分類が頻出。',
      '精度と解釈可能性のトレードオフが基本概念。深層学習は高精度だが解釈困難。',
      '医療・金融・法律分野での説明責任（accountability）との関連が出題される。',
    ],
  },
  {
    termId: 'transparency',
    points: [
      '解釈可能性（interpretability）との違い：透明性はモデルの内部構造が観察可能であること、解釈可能性は人間が理解できること。',
      'モデルの複雑さ（パラメータ数）と透明性は反比例する傾向がある点を理解する。',
      'EU AI Act等の規制でAIの透明性が求められる社会的背景を把握する。',
    ],
  },
  {
    termId: 'integrated-gradients',
    points: [
      'ベースライン（例：黒画像）から実際の入力まで直線パスに沿って勾配を積分する手法。',
      '2つの公理（感度・実装不変性）を満たす理論的に優れた帰属手法であることが重要。',
      'Saliency Mapの改良版として位置づけられる。勾配消失問題を積分により回避する点がポイント。',
    ],
    formula: 'IG_i(x) = (x_i - x\'_i) × ∫_0^1 (∂F(x\' + α(x-x\'))/∂x_i) dα',
  },
];
